{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### TAO remote client - Classification\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "![image](https://developer.nvidia.com/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
    "\n",
    "### Sample prediction for an Image Classification model\n",
    "<img align=\"center\" src=\"../example_images/sample_image_classification.jpg\">\n",
    "\n",
    "### The workflow in a nutshell\n",
    "\n",
    "- Creating a dataset\n",
    "- Upload dataset to the service\n",
    "- Getting a PTM from NGC\n",
    "- Model Actions\n",
    "    - Train (Normal/AutoML)\n",
    "    - Evaluate\n",
    "    - Prune, retrain\n",
    "    - Export\n",
    "    - Tao-Deploy\n",
    "    - Inference on TAO\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [Install TAO remote client ](#head-1)\n",
    "1. [Set the remote service base URL](#head-2)\n",
    "1. [Access the shared volume](#head-3)\n",
    "1. [Create the datasets](#head-4)\n",
    "1. [List datasets](#head-5)\n",
    "1. [Create a model experiment](#head-8)\n",
    "1. [Find pretrained model](#head-9)\n",
    "1. [Customize model metadata](#head-10)\n",
    "1. [View hyperparameters that are enabled for AutoML by default](#head-11)\n",
    "1. [Set AutoML related configurations](#head-12)\n",
    "1. [Provide train specs](#head-13)\n",
    "1. [Run train](#head-14)\n",
    "1. [View checkpoint files](#head-15)\n",
    "1. [Provide evaluate specs](#head-16)\n",
    "1. [Run evaluate](#head-17)\n",
    "1. [Provide prune specs](#head-18)\n",
    "1. [Run prune](#head-19)\n",
    "1. [Provide retrain specs](#head-20)\n",
    "1. [Run retrain](#head-21)\n",
    "1. [Run evaluate on retrain](#head-21-1)\n",
    "1. [Provide export specs](#head-22)\n",
    "1. [Run export](#head-23)\n",
    "1. [Provide trt engine generation specs](#head-26)\n",
    "1. [Run TRT Engine generation using TAO-Deploy](#head-27)\n",
    "1. [Provide TAO inference specs](#head-28)\n",
    "1. [Run TAO inference](#head-29)\n",
    "1. [Delete experiment](#head-30)\n",
    "1. [Delete datasets](#head-31)\n",
    "1. [Unmount shared volume](#head-32)\n",
    "1. [Uninstall TAO Remote Client](#head-33)\n",
    "\n",
    "### Requirements\n",
    "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import getpass\n",
    "import uuid\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "namespace = 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "1. Assign a model_name in FIXME 1\n",
    "1. Assign the ip_address and port_number in FIXME 2 and FIXME 3 ([info](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_rest_api.html))\n",
    "1. Assign the ngc_api_key variable in FIXME 4\n",
    "1. (Optional) Enable AutoML if needed in FIXME 5\n",
    "1. Choose between default and custom dataset in FIXME 6\n",
    "1. Assign path of DATA_DIR in FIXME 7\n",
    "1. Choose between Bayesian and Hyperband automl_algorithm in FIXME 8 (If automl was enabled in FIXME5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Available models (#FIXME 1):\n",
    "# 1. classification-pyt - https://docs.nvidia.com/tao/tao-toolkit/text/image_classification.html\n",
    "# 2. classification-tf1 - https://docs.nvidia.com/tao/tao-toolkit/text/image_classification.html\n",
    "# 3. classification-tf2 - https://docs.nvidia.com/tao/tao-toolkit/text/image_classification_tf2.html\n",
    "# 4. multitask-classification - https://docs.nvidia.com/tao/tao-toolkit/text/multitask_image_classification.html\n",
    "# classification is the same as multi-class classification\n",
    "\n",
    "model_name = \"multitask-classification\"  # FIXME1 (Add the model name from the above mentioned list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Install TAO remote client <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SKIP this step IF you have already installed the TAO-Client wheel.\n",
    "! pip3 install nvidia-tao-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View the version of the TAO-Client\n",
    "! tao-client --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Set the remote service base URL <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the node_addr and port number\n",
    "node_addr = \"<ip_address>\" # FIXME2 example: 10.137.149.22\n",
    "node_port = \"<port_number>\" # FIXME3 example: 32334\n",
    "# In host machine, node ip_address and port number can be obtained as follows,\n",
    "# ip_address: hostname -i\n",
    "# port_number: kubectl get service ingress-nginx-controller -o jsonpath='{.spec.ports[0].nodePort}'\n",
    "\n",
    "ngc_api_key = \"<ngc_api_key>\" # FIXME4 (Add NGC API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "automl_enabled = False # FIXME5 set to True if you want to run automl for the model chosen in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env BASE_URL=http://{node_addr}:{node_port}/{namespace}/api/v1\n",
    "\n",
    "# Exchange NGC_API_KEY for JWT\n",
    "identity = json.loads(subprocess.getoutput(f'tao-client login --ngc-api-key {ngc_api_key}'))\n",
    "\n",
    "%env USER={identity['user_id']}\n",
    "%env TOKEN={identity['token']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Access the shared volume <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get PVC ID\n",
    "pvc_id = subprocess.getoutput(f'kubectl get pvc tao-toolkit-api-pvc -n {namespace} -o jsonpath=\"{{.spec.volumeName}}\"')\n",
    "print(pvc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get NFS server info\n",
    "provisioner = json.loads(subprocess.getoutput(f'helm get values nfs-subdir-external-provisioner -o json'))\n",
    "nfs_server = provisioner['nfs']['server']\n",
    "nfs_path = provisioner['nfs']['path']\n",
    "print(nfs_server, nfs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "user = getpass.getuser()\n",
    "home = os.path.expanduser('~')\n",
    "\n",
    "! echo \"Password for {user}\"\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mount shared volume \n",
    "! mkdir -p ~/shared\n",
    "\n",
    "command = \"apt-get -y install nfs-common >> /dev/null\"\n",
    "! echo {password} | sudo -S -k {command}\n",
    "\n",
    "command = f\"mount -t nfs {nfs_server}:{nfs_path}/{namespace}-tao-toolkit-api-pvc-{pvc_id} ~/shared\"\n",
    "! echo {password} | sudo -S -k {command} && echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Create the datasets <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "**For multi-class classification:**\n",
    "\n",
    "We will be using the `pascal VOC dataset` for the tutorial. To find more details please visit [here](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#devkit). Please download the dataset present [here](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar) to the environment variable $DATA_DIR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If using custom dataset; it should follow this dataset structure, and skip running** \"**Split dataset into train and val sets**\"\n",
    "```\n",
    "DATA_DIR\n",
    "├── classes.txt\n",
    "├── images_test\n",
    "│   ├── class_name_1\n",
    "│   │   ├── image_name_1.jpg\n",
    "│   │   ├── image_name_2.jpg\n",
    "│   │   ├── ...\n",
    "|   |   ... \n",
    "│   └── class_name_n\n",
    "│       ├── image_name_3.jpg\n",
    "│       ├── image_name_4.jpg\n",
    "│       ├── ...\n",
    "├── images_train\n",
    "│   ├── class_name_1\n",
    "│   │   ├── image_name_5.jpg\n",
    "│   │   ├── image_name_6.jpg\n",
    "|   |   ...\n",
    "│   └── class_name_n\n",
    "│       ├── image_name_7.jpg\n",
    "│       ├── image_name_8.jpg\n",
    "│       ├── ...\n",
    "|\n",
    "└── images_val\n",
    "    ├── class_name_1\n",
    "    │   ├── image_name_9.jpg\n",
    "    │   ├── image_name_10.jpg\n",
    "    │   ├── ...\n",
    "    |   ...\n",
    "    └── class_name_n\n",
    "        ├── image_name_11.jpg\n",
    "        ├── image_name_12.jpg\n",
    "        ├── ...\n",
    "```\n",
    "- Each class name folder should contain the images corresponding to that class\n",
    "- Same class name folders should be present across images_test, images_train and images_val\n",
    "- classes.txt is a file which contains the names of all classes (each name in a separate line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For multi-task classification:**\n",
    "\n",
    "We will be using the Fashion Product Images (Small) for the tutorial. This dataset is available on Kaggle.In this tutorial, our trained classification network will perform three tasks: article category classification, base color classification and target season classification.\n",
    "\n",
    "To download the dataset, you will need a Kaggle account. After login, you can download the dataset zip file [here](https://www.kaggle.com/paramaggarwal/fashion-product-images-small). The downloaded file is archive.zip with a subfolder called myntradataset. Unzip contents in this subfolder to your workdir created in the cell above and you should have a folder called images and a CSV file called styles.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If using custom dataset; it should follow this dataset structure**\n",
    "```\n",
    "DATA_DIR\n",
    "├── images\n",
    "│   ├── image_name_1.jpg\n",
    "│   ├── image_name_2.jpg\n",
    "|   |   ├── ...\n",
    "├── styles.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_to_be_used = \"default\" # FIXME6 example: default/custom; default for the dataset used in this tutorial notebook; custom for a different dataset\n",
    "DATA_DIR = model_name # FIXME7\n",
    "os.environ['DATA_DIR']= DATA_DIR\n",
    "!mkdir -p $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_to_be_used == \"default\":\n",
    "    if \"classification-\" in model_name:\n",
    "        if not os.path.exists(os.path.join(DATA_DIR,\"VOCtrainval_11-May-2012.tar\")):\n",
    "            print(\"Download VOC tar data into \", DATA_DIR)\n",
    "        else:\n",
    "            !tar -xf $DATA_DIR/VOCtrainval_11-May-2012.tar -C $DATA_DIR\n",
    "    elif model_name == \"multitask-classification\":\n",
    "        if not os.path.exists(os.path.join(DATA_DIR,\"archive.zip\")):\n",
    "            print(f\"Download Fashion zip data into \", DATA_DIR)\n",
    "        else:\n",
    "            !unzip -uq $DATA_DIR/archive.zip -d $DATA_DIR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset is present\n",
    "if \"classification-\" in model_name and dataset_to_be_used == \"default\":\n",
    "    !if [ ! -d $DATA_DIR/VOCdevkit ]; then echo 'Images folder NOT found.'; else echo 'Found images folder.';fi\n",
    "    !rm -rf $DATA_DIR/split\n",
    "elif model_name == \"multitask-classification\":\n",
    "    !if [ ! -d $DATA_DIR/images ]; then echo 'Images folder NOT found.'; else echo 'Found images folder.';fi\n",
    "    !if [ ! -f $DATA_DIR/styles.csv ]; then echo 'CSV file NOT found.'; else echo 'Found CSV file.';fi\n",
    "    # Create subdirectories and remove existing files in them\n",
    "    !mkdir -p $DATA_DIR/images_train && rm -rf $DATA_DIR/images_train/*\n",
    "    !mkdir -p $DATA_DIR/images_val && rm -rf $DATA_DIR/images_val/*\n",
    "    !mkdir -p $DATA_DIR/images_test && rm -rf $DATA_DIR/images_test/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and val sets\n",
    "if \"classification-\" in model_name and dataset_to_be_used == \"default\":\n",
    "    !python3 -m pip install tqdm\n",
    "    from os.path import join as join_path\n",
    "    import os\n",
    "    import glob\n",
    "    import re\n",
    "    import shutil\n",
    "\n",
    "    DATA_DIR=os.environ.get('DATA_DIR')\n",
    "    source_dir = join_path(DATA_DIR, \"VOCdevkit/VOC2012\")\n",
    "    target_dir = join_path(DATA_DIR, \"formatted\")\n",
    "\n",
    "    suffix = '_trainval.txt'\n",
    "    classes_dir = join_path(source_dir, \"ImageSets\", \"Main\")\n",
    "    images_dir = join_path(source_dir, \"JPEGImages\")\n",
    "    classes_files = glob.glob(classes_dir+\"/*\"+suffix)\n",
    "    class_names = []\n",
    "    for file in classes_files:\n",
    "        # get the filename and make output class folder\n",
    "        classname = os.path.basename(file)\n",
    "        if classname.endswith(suffix):\n",
    "            classname = classname[:-len(suffix)]\n",
    "            target_dir_path = join_path(target_dir, classname)\n",
    "            if not os.path.exists(target_dir_path):\n",
    "                os.makedirs(target_dir_path)\n",
    "        else:\n",
    "            continue\n",
    "        print(classname)\n",
    "        class_names.append(classname)\n",
    "\n",
    "        with open(file) as f:\n",
    "            content = f.readlines()\n",
    "\n",
    "        for line in content:\n",
    "            tokens = re.split('\\s+', line)\n",
    "            if tokens[1] == '1':\n",
    "                # copy this image into target dir_path\n",
    "                target_file_path = join_path(target_dir_path, tokens[0] + '.jpg')\n",
    "                src_file_path = join_path(images_dir, tokens[0] + '.jpg')\n",
    "                shutil.copyfile(src_file_path, target_file_path)\n",
    "\n",
    "    from random import shuffle\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    DATA_DIR=os.environ.get('DATA_DIR')\n",
    "    SOURCE_DIR=os.path.join(DATA_DIR, 'formatted')\n",
    "    TARGET_DIR=os.path.join(DATA_DIR,'split')\n",
    "    # list dir\n",
    "    print(os.walk(SOURCE_DIR))\n",
    "    dir_list = next(os.walk(SOURCE_DIR))[1]\n",
    "    # for each dir, create a new dir in split\n",
    "    for dir_i in tqdm(dir_list):\n",
    "        newdir_train = os.path.join(TARGET_DIR, 'images_train', dir_i)\n",
    "        newdir_val = os.path.join(TARGET_DIR, 'images_val', dir_i)\n",
    "        newdir_test = os.path.join(TARGET_DIR, 'images_test', dir_i)\n",
    "\n",
    "        if not os.path.exists(newdir_train):\n",
    "                os.makedirs(newdir_train)\n",
    "        if not os.path.exists(newdir_val):\n",
    "                os.makedirs(newdir_val)\n",
    "        if not os.path.exists(newdir_test):\n",
    "                os.makedirs(newdir_test)\n",
    "\n",
    "        img_list = glob.glob(os.path.join(SOURCE_DIR, dir_i, '*.jpg'))\n",
    "        # shuffle data\n",
    "        shuffle(img_list)\n",
    "\n",
    "        for j in range(int(len(img_list)*0.7)):\n",
    "                shutil.copy2(img_list[j], os.path.join(TARGET_DIR, 'images_train', dir_i))\n",
    "\n",
    "        for j in range(int(len(img_list)*0.7), int(len(img_list)*0.8)):\n",
    "                shutil.copy2(img_list[j], os.path.join(TARGET_DIR, 'images_val', dir_i))\n",
    "\n",
    "        for j in range(int(len(img_list)*0.8), len(img_list)):\n",
    "                shutil.copy2(img_list[j], os.path.join(TARGET_DIR, 'images_test', dir_i))\n",
    "\n",
    "    with open(f'{DATA_DIR}/classes.txt', 'w') as f:\n",
    "        for class_name in class_names:\n",
    "            f.write(f\"{class_name}\\n\")\n",
    "\n",
    "    shutil.copy2(f'{DATA_DIR}/classes.txt',TARGET_DIR)\n",
    "    print('Done splitting dataset.')\n",
    "\n",
    "elif model_name == \"multitask-classification\" and dataset_to_be_used == \"default\":\n",
    "    !python3 -m pip install numpy\n",
    "    !python3 -m pip install pandas==1.5.1\n",
    "    import os\n",
    "    import shutil\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(os.environ['DATA_DIR'] + '/styles.csv', on_bad_lines='skip')\n",
    "    df = df[['id', 'baseColour', 'subCategory', 'season']]\n",
    "    df = df.dropna()\n",
    "    category_cls = df.subCategory.value_counts()[:10].index # 10-class multitask-classification\n",
    "    season_cls = ['Spring', 'Summer', 'Fall', 'Winter'] # 4-class multitask-classification\n",
    "    color_cls = df.baseColour.value_counts()[:11].index # 11-class multitask-classification\n",
    "\n",
    "    # Get all valid rows\n",
    "    df = df[df.subCategory.isin(category_cls) & df.season.isin(season_cls) & df.baseColour.isin(color_cls)]\n",
    "    df.columns = ['fname', 'base_color', 'category', 'season']\n",
    "    df.fname = df.fname.astype(str)\n",
    "    df.fname = df.fname + '.jpg'\n",
    "\n",
    "    # remove entries whose image file is missing\n",
    "    all_img_files = os.listdir(os.environ['DATA_DIR'] + '/images')\n",
    "    df = df[df.fname.isin(all_img_files)]\n",
    "\n",
    "    idx = np.arange(len(df))\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    train_split_idx = int(len(df)*0.8)\n",
    "    train_df = df.iloc[idx[:train_split_idx]]\n",
    "    val_df = df.iloc[idx[train_split_idx:train_split_idx+(len(df) // 10)]]\n",
    "    test_df = df.iloc[idx[train_split_idx+(len(df) // 10):]]\n",
    "\n",
    "    # Add a simple sanity check\n",
    "    assert len(train_df.season.unique()) == 4 and len(train_df.base_color.unique()) == 11 and \\\n",
    "        len(train_df.category.unique()) == 10, 'Training set misses some classes, re-run this cell!'\n",
    "    assert len(val_df.season.unique()) == 4 and len(val_df.base_color.unique()) == 11 and \\\n",
    "        len(val_df.category.unique()) == 10, 'Validation set misses some classes, re-run this cell!'\n",
    "    assert len(test_df.season.unique()) == 4 and len(test_df.base_color.unique()) == 11 and \\\n",
    "        len(test_df.category.unique()) == 10, 'Test set misses some classes, re-run this cell!'\n",
    "\n",
    "    for image_name in train_df[\"fname\"]:\n",
    "        source_file_name = os.path.join(DATA_DIR, \"images\", image_name)\n",
    "        destination_file_name = os.path.join(DATA_DIR, \"images_train\", image_name)\n",
    "        shutil.copy(source_file_name, destination_file_name)\n",
    "\n",
    "    for image_name in val_df[\"fname\"]:\n",
    "        source_file_name = os.path.join(DATA_DIR, \"images\", image_name)\n",
    "        destination_file_name = os.path.join(DATA_DIR, \"images_train\", image_name)\n",
    "        shutil.copy(source_file_name, destination_file_name)\n",
    "        destination_file_name = os.path.join(DATA_DIR, \"images_val\", image_name)\n",
    "        shutil.copy(source_file_name, destination_file_name)\n",
    "\n",
    "    for image_name in test_df[\"fname\"]:\n",
    "        source_file_name = os.path.join(DATA_DIR, \"images\", image_name)\n",
    "        destination_file_name = os.path.join(DATA_DIR, \"images_test\", image_name)\n",
    "        shutil.copy(source_file_name, destination_file_name)\n",
    "\n",
    "    # save processed data labels\n",
    "    train_df.to_csv(os.environ['DATA_DIR'] + '/train.csv', index=False)\n",
    "    val_df.to_csv(os.environ['DATA_DIR'] + '/val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# verify\n",
    "if \"classification-\" in model_name:\n",
    "    !if [ ! -d $DATA_DIR/split/images_train ]; then echo 'train folder NOT found.'; else echo 'Found train images folder.';fi\n",
    "    !if [ ! -d $DATA_DIR/split/images_val ]; then echo 'val folder NOT found.'; else echo 'Found val images folder.';fi\n",
    "    !if [ ! -d $DATA_DIR/split/images_test ]; then echo 'test folder NOT found.'; else echo 'Found test images folder.';fi\n",
    "    !if [ ! -f $DATA_DIR/split/classes.txt ]; then echo 'classes.txt not found'; else echo 'Found classes.txt.';fi\n",
    "elif model_name == \"multitask-classification\":\n",
    "    import pandas as pd\n",
    "\n",
    "    print(\"Number of images in the train set. {}\".format(\n",
    "        len(pd.read_csv(os.environ['DATA_DIR'] + '/train.csv'))\n",
    "    ))\n",
    "    print(\"Number of images in the validation set. {}\".format(\n",
    "        len(pd.read_csv(os.environ['DATA_DIR'] + '/val.csv'))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and upload datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_name == \"classification-pyt\":\n",
    "    ds_format = \"classification_pyt\"\n",
    "elif \"classification-\" in model_name:\n",
    "    ds_format = \"default\"\n",
    "elif model_name == \"multitask-classification\":\n",
    "    ds_format = \"custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_id = subprocess.getoutput(f\"tao-client {model_name} dataset-create --dataset_type image_classification --dataset_format {ds_format}\")\n",
    "print(train_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"classification-\" in model_name:\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/split/images_train ~/shared/users/{os.environ['USER']}/datasets/{train_dataset_id}/\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/split/classes.txt ~/shared/users/{os.environ['USER']}/datasets/{train_dataset_id}/\n",
    "elif model_name == \"multitask-classification\":\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/images_train ~/shared/users/{os.environ['USER']}/datasets/{train_dataset_id}/\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/train.csv ~/shared/users/{os.environ['USER']}/datasets/{train_dataset_id}/\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/val.csv ~/shared/users/{os.environ['USER']}/datasets/{train_dataset_id}/\n",
    "! echo DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataset_id = subprocess.getoutput(f\"tao-client {model_name} dataset-create --dataset_type image_classification --dataset_format {ds_format}\")\n",
    "print(eval_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"classification-\" in model_name:\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/split/images_val ~/shared/users/{os.environ['USER']}/datasets/{eval_dataset_id}/\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/split/classes.txt ~/shared/users/{os.environ['USER']}/datasets/{eval_dataset_id}/\n",
    "elif model_name == \"multitask-classification\":\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/images_val ~/shared/users/{os.environ['USER']}/datasets/{eval_dataset_id}\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/val.csv ~/shared/users/{os.environ['USER']}/datasets/{eval_dataset_id}/\n",
    "! echo DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset_id = subprocess.getoutput(f\"tao-client {model_name} dataset-create --dataset_type image_classification --dataset_format raw\")\n",
    "print(test_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"classification-\" in model_name:\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/split/images_test ~/shared/users/{os.environ['USER']}/datasets/{test_dataset_id}/\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/split/classes.txt ~/shared/users/{os.environ['USER']}/datasets/{test_dataset_id}/\n",
    "elif model_name == \"multitask-classification\":\n",
    "    ! rsync -ah --info=progress2 {DATA_DIR}/images_test ~/shared/users/{os.environ['USER']}/datasets/{test_dataset_id}\n",
    "! echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### List datasets <a class=\"anchor\" id=\"head-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pattern = os.path.join(home, 'shared', 'users', os.environ['USER'], 'datasets', '*', 'metadata.json')\n",
    "\n",
    "datasets = []\n",
    "for metadata_path in glob.glob(pattern):\n",
    "    with open(metadata_path, 'r') as metadata_file:\n",
    "        datasets.append(json.load(metadata_file))\n",
    "\n",
    "print(json.dumps(datasets, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Create a model experiment <a class=\"anchor\" id=\"head-6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_arch = model_name.replace(\"-\",\"_\")\n",
    "if \"classification_\" in network_arch:\n",
    "    encode_key = \"nvidia_tlt\"\n",
    "else:\n",
    "    encode_key = \"tlt_encode\"\n",
    "model_id = subprocess.getoutput(f\"tao-client {model_name} model-create --network_arch {network_arch} --encryption_key {encode_key} \")\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Find pretrained model <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all pretrained models for the chosen network architecture\n",
    "pattern = os.path.join(home, 'shared', 'users', '*', 'models', '*', 'metadata.json')\n",
    "\n",
    "for ptm_metadata_path in glob.glob(pattern):\n",
    "  with open(ptm_metadata_path, 'r') as metadata_file:\n",
    "    ptm_metadata = json.load(metadata_file)\n",
    "    metadata_network_arch = ptm_metadata.get(\"network_arch\")\n",
    "    if metadata_network_arch == network_arch:\n",
    "      if \"encryption_key\" not in ptm_metadata.keys():\n",
    "        print(f'PTM Name: {ptm_metadata[\"name\"]}; PTM version: {ptm_metadata[\"version\"]}; NGC PATH: {ptm_metadata[\"ngc_path\"]}; Additional info: {ptm_metadata[\"additional_id_info\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assigning pretrained models to different classification models\n",
    "# From the output of previous cell make the appropriate changes to this map if you want to change the default PTM backbone.\n",
    "# Changing the default backbone here requires changing default spec/config during train/eval etc like for example\n",
    "# If you are changing the ptm to resnet34, then you have to modify the config key num_layers if it exists to 34 manually\n",
    "pretrained_map = {\"classification_tf1\" : \"pretrained_classification:resnet18\",\n",
    "                  \"classification_tf2\" : \"pretrained_classification_tf2:efficientnet_b0\",\n",
    "                  \"classification_pyt\" : \"pretrained_fan_classification_imagenet:fan_hybrid_tiny\",\n",
    "                  \"multitask_classification\" : \"pretrained_classification:resnet10\"}\n",
    "no_ptm_models = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if network_arch not in no_ptm_models:\n",
    "    pattern = os.path.join(home, 'shared', 'users', '*', 'models', '*', 'metadata.json')\n",
    "\n",
    "    ptm = []\n",
    "    for ptm_metadata_path in glob.glob(pattern):\n",
    "      with open(ptm_metadata_path, 'r') as metadata_file:\n",
    "        ptm_metadata = json.load(metadata_file)\n",
    "        ngc_path = ptm_metadata.get(\"ngc_path\")\n",
    "        metadata_network_arch = ptm_metadata.get(\"network_arch\")\n",
    "        if metadata_network_arch == network_arch and ngc_path.endswith(pretrained_map[network_arch]):\n",
    "          ptm = [ptm_metadata[\"id\"]]\n",
    "          break\n",
    "\n",
    "    print(ptm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Customize model metadata <a class=\"anchor\" id=\"head-10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'metadata.json')\n",
    "\n",
    "with open(metadata_path , \"r\") as metadata_file:\n",
    "    metadata = json.load(metadata_file)\n",
    "\n",
    "metadata[\"train_datasets\"] = [train_dataset_id]\n",
    "metadata[\"eval_dataset\"] = eval_dataset_id\n",
    "metadata[\"inference_dataset\"] = test_dataset_id\n",
    "metadata[\"calibration_dataset\"] = train_dataset_id\n",
    "if network_arch not in no_ptm_models:\n",
    "    metadata[\"ptm\"] = ptm\n",
    "\n",
    "with open(metadata_path, \"w\") as metadata_file:\n",
    "    json.dump(metadata, metadata_file, indent=2)\n",
    "\n",
    "print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View hyperparameters that are enabled for AutoML by default <a class=\"anchor\" id=\"head-11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if automl_enabled:\n",
    "    # View default automl specs enabled\n",
    "    ! tao-client {model_name} model-automl-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/automl_defaults.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Set AutoML related configurations <a class=\"anchor\" id=\"head-12\"></a>\n",
    "Refer to these hyper-links to see the parameters supported by each network and add more parameters if necessary in addition to the default automl enabled parameters: \n",
    "\n",
    "[Classification TF1](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/classification_tf1/classification_tf1%20-%20train.csv), \n",
    "[Classification TF2](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/classification_tf2/classification_tf2%20-%20train.csv), \n",
    "[Classification Pytorch](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/classification_pyt/classification_pyt%20-%20train.csv), \n",
    "[Multitask classification](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/multitask_classification/multitask_classification%20-%20train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if automl_enabled:\n",
    "    # Choose automl algorithm between \"Bayesian\" and \"HyperBand\".\n",
    "    automl_algorithm=\"Bayesian\" # FIXME8 example: Bayesian/HyperBand\n",
    "\n",
    "    if model_name == \"classification-pyt\":\n",
    "        metric = \"loss\"\n",
    "    else:\n",
    "        metric = \"kpi\" \n",
    "\n",
    "    additional_automl_parameters = [] #Refer to parameter list mentioned in the above links and add any extra parameter in addition to the default enabled ones\n",
    "    remove_default_automl_parameters = [] #Remove any hyperparameters that are enabled by default for AutoML\n",
    "\n",
    "    metadata[\"automl_algorithm\"] = automl_algorithm\n",
    "    metadata[\"automl_enabled\"] = automl_enabled\n",
    "    metadata[\"metric\"] = metric\n",
    "    metadata[\"epoch_multiplier\"] = 1 # Will be considered for Hyperband only\n",
    "    metadata[\"automl_add_hyperparameters\"] = str(additional_automl_parameters)\n",
    "    metadata[\"automl_remove_hyperparameters\"] = str(remove_default_automl_parameters)\n",
    "\n",
    "    with open(metadata_path, \"w\") as metadata_file:\n",
    "        json.dump(metadata, metadata_file, indent=2)\n",
    "\n",
    "    print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Provide train specs <a class=\"anchor\" id=\"head-13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Default train model specs\n",
    "! tao-client {model_name} model-train-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Customize train model specs\n",
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'specs', 'train.json')\n",
    "\n",
    "with open(specs_path , \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "# Example for multitask-classification (for each network the parameter key might be different)\n",
    "if model_name == \"multitask-classification\":\n",
    "    specs[\"training_config\"][\"num_epochs\"] = 10\n",
    "    specs[\"gpus\"] = 1\n",
    "# Example for classification-pyt\n",
    "elif model_name == \"classification-pyt\":\n",
    "    specs[\"train\"][\"train_config\"][\"runner\"][\"max_epochs\"] = 40\n",
    "    specs[\"train\"][\"num_gpus\"] = 1\n",
    "    specs[\"gpus\"] = 1\n",
    "# Example for classification-tf1\n",
    "elif model_name == \"classification-tf1\":\n",
    "    specs[\"train_config\"][\"n_epochs\"] = 80\n",
    "    specs[\"gpus\"] = 1\n",
    "# Example for classification-tf2\n",
    "elif model_name == \"classification-tf2\":\n",
    "    specs[\"train\"][\"num_epochs\"] = 80\n",
    "    specs[\"gpus\"] = 1\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Run train <a class=\"anchor\" id=\"head-14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_job_id = subprocess.getoutput(f\"tao-client {model_name} model-train --id \" + model_id)\n",
    "print(train_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def my_tail(logs_dir, log_file):\n",
    "    %env LOG_FILE={logs_dir}/{log_file}\n",
    "    ! mkdir -p {logs_dir}\n",
    "    ! [ ! -f \"$LOG_FILE\" ] && touch $LOG_FILE && chmod 666 $LOG_FILE\n",
    "    ! tail -f -n +1 $LOG_FILE | while read LINE; do echo \"$LINE\"; [[ \"$LINE\" == \"EOF\" ]] && pkill -P $$ tail; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Monitor job status\n",
    "if automl_enabled:\n",
    "    # Set poll_automl_stats to True if just want to see what's the time left, how many epochs are remaining etc.\n",
    "    # Set poll_automl_stats to False if you want to skip stats and see the training logs instead. Training logs viewing are supported only for Bayesian\n",
    "\n",
    "    # For automl: Training times for different models benchmarked on 1 GPU V100 machine can be found here: https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#results-of-automl-experiments\n",
    "    \n",
    "    poll_automl_stats = True\n",
    "    if poll_automl_stats:\n",
    "        import time\n",
    "        from IPython.display import clear_output\n",
    "        stats_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, train_job_id, \"automl_metadata.json\")\n",
    "        controller_json_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, train_job_id, \"controller.json\")\n",
    "        while True:\n",
    "            time.sleep(15)\n",
    "            clear_output(wait=True)\n",
    "            if os.path.exists(stats_path):\n",
    "                try:\n",
    "                    with open(stats_path , \"r\") as stats_file:\n",
    "                        stats_dict = json.load(stats_file)\n",
    "                    print(json.dumps(stats_dict, indent=2))\n",
    "                    if float(stats_dict.get(\"Number of epochs yet to start\",-1)) == 0.0 or float(stats_dict.get(\"Number of iters yet to start\",-1)) == 0.0:\n",
    "                        break\n",
    "                except (json.JSONDecodeError):\n",
    "                    print(\"Stats computed are being written to file. Stats will be visible on screen in a few seconds\")\n",
    "    else:\n",
    "        # Print the log file - supported only for bayesian (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "        if automl_algorithm == \"Bayesian\":\n",
    "            logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id)\n",
    "            max_recommendations = metadata.get(\"automl_max_recommendations\",20)\n",
    "            for experiment_num in range(max_recommendations):\n",
    "                log_file = f\"{train_job_id}/experiment_{experiment_num}/log.txt\"\n",
    "                while True:\n",
    "                    if os.path.exists(os.path.join(logs_dir, log_file)):\n",
    "                        break\n",
    "                print(f\"\\n\\nViewing experiment {experiment_num}\\n\\n\")\n",
    "                my_tail(logs_dir, log_file)\n",
    "    \n",
    "else:\n",
    "    # Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "    logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'logs')\n",
    "    log_file = f\"{train_job_id}.txt\"\n",
    "\n",
    "    my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To Stop an AutoML JOB\n",
    "#    1. Stop the 'Monitor job status' cell (the cell right before this cell) manually\n",
    "#    2. Uncomment the snippet in the next cell and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if automl_enabled:\n",
    "#     canceled_job_id = subprocess.getoutput(f\"tao-client {model_name} model-job-cancel --id {model_id} --job {train_job_id}\")\n",
    "#     print(canceled_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resume AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the below snippet if you want to resume an already stopped AutoML job and then run the 'Monitor job status' cell above (4th cell above from this cell)\n",
    "# if automl_enabled:\n",
    "#     resumed_job_id = subprocess.getoutput(f\"tao-client {model_name} model-job-resume --id {model_id} --job {train_job_id}\")\n",
    "#     print(resumed_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Viewing checkpoint files <a class=\"anchor\" id=\"head-15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the checkpoints generated for the training job and for automl jobs, in addition view: best performing model's config and the results of all automl experiments\n",
    "\n",
    "job_dir = f\"{home}/shared/users/{os.environ['USER']}/models/{model_id}/{train_job_id}\"\n",
    "model_path = job_dir\n",
    "\n",
    "if automl_enabled:\n",
    "    !python3 -m pip install pandas==1.5.1\n",
    "    import pandas as pd\n",
    "    import glob\n",
    "    model_path =  f\"{job_dir}/best_model\"\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    if os.path.exists(model_path) and len(os.listdir(model_path)) > 0:\n",
    "        #List the binary model file\n",
    "        print(\"\\nCheckpoints for the training experiment\")\n",
    "        if os.path.exists(model_path+\"/train/weights\") and len(os.listdir(model_path+\"/train/weights\")) > 0:\n",
    "            print(f\"Folder: {model_path}/train/weights\")\n",
    "            print(\"Files:\", os.listdir(model_path+\"/train/weights\"))\n",
    "        elif os.path.exists(model_path+\"/weights\") and len(os.listdir(model_path+\"/weights\")) > 0:\n",
    "            print(f\"Folder: {model_path}/weights\")\n",
    "            print(\"Files:\", os.listdir(model_path+\"/weights\"))\n",
    "        else:\n",
    "            print(f\"Folder: {model_path}\")\n",
    "            print(\"Files:\", os.listdir(model_path))\n",
    "\n",
    "        if automl_enabled:\n",
    "            if os.path.exists(f\"{model_path}/controller.json\") and (len(glob.glob(os.path.join(model_path,\"*.protobuf\"))) > 0 or len(glob.glob(os.path.join(model_path,\"*.yaml\"))) > 0):\n",
    "                experiment_artifacts = json.load(open(f\"{model_path}/controller.json\",\"r\"))\n",
    "                data_frame = pd.DataFrame(experiment_artifacts)\n",
    "                # Print experiment id/number and the corresponding result\n",
    "                print(\"\\nResults of all experiments\")\n",
    "                with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "                    print(data_frame[[\"id\",\"result\"]])\n",
    "                break\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide evaluate specs <a class=\"anchor\" id=\"head-16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default evaluate model specs\n",
    "! tao-client {model_name} model-evaluate-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/evaluate.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize evaluate model specs\n",
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'specs', 'evaluate.json')\n",
    "\n",
    "with open(specs_path , \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "# Change any spec if you wish\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluate <a class=\"anchor\" id=\"head-17\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_job_id = subprocess.getoutput(f\"tao-client {model_name} model-evaluate --id {model_id} --job {train_job_id}\")\n",
    "print(eval_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "log_file = f\"{eval_job_id}.txt\"\n",
    "logs_dir = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'logs')\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Provide prune specs <a class=\"anchor\" id=\"head-18\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name != \"classification-pyt\":\n",
    "    # Default prune model specs\n",
    "    ! tao-client {model_name} model-prune-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/prune.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_name != \"classification-pyt\":\n",
    "    # Customize retrain model specs\n",
    "    specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'specs', 'prune.json')\n",
    "\n",
    "    with open(specs_path , \"r\") as specs_file:\n",
    "        specs = json.load(specs_file)\n",
    "\n",
    "    # Apply changes to specs dictionary if required here\n",
    "    if model_name == \"classification-tf2\":\n",
    "        specs[\"prune\"][\"byom_model_path\"] = \"\"\n",
    "\n",
    "    with open(specs_path, \"w\") as specs_file:\n",
    "        json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "    print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Run prune <a class=\"anchor\" id=\"head-19\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name != \"classification-pyt\":\n",
    "    prune_job_id = subprocess.getoutput(f\"tao-client {model_name} model-prune --id {model_id} --job {train_job_id}\")\n",
    "    print(prune_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name != \"classification-pyt\":\n",
    "    # Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "    log_file = f\"{prune_job_id}.txt\"\n",
    "    my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Provide retrain specs <a class=\"anchor\" id=\"head-20\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name != \"classification-pyt\":\n",
    "    # Default retrain model specs\n",
    "    ! tao-client {model_name} model-retrain-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/retrain.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name != \"classification-pyt\":\n",
    "    # Customize retrain model specs\n",
    "    specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'specs', 'retrain.json')\n",
    "\n",
    "    with open(specs_path , \"r\") as specs_file:\n",
    "        specs = json.load(specs_file)\n",
    "\n",
    "    # Override any of the parameters listed in the previous cell as required\n",
    "    # Example for multitask-classification (for each network the parameter key might be different)\n",
    "    if model_name == \"multitask-classification\":\n",
    "        specs[\"training_config\"][\"num_epochs\"] = 10\n",
    "        specs[\"gpus\"] = 1\n",
    "    # Example for classification_tf1\n",
    "    elif model_name == \"classification-tf1\":\n",
    "        specs[\"train_config\"][\"n_epochs\"] = 80\n",
    "        specs[\"gpus\"] = 1\n",
    "    # Example for classification_tf2\n",
    "    elif model_name == \"classification-tf2\":\n",
    "        specs[\"train\"][\"num_epochs\"] = 80\n",
    "        specs[\"gpus\"] = 1\n",
    "\n",
    "    with open(specs_path, \"w\") as specs_file:\n",
    "        json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "    print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Run retrain <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name != \"classification-pyt\":\n",
    "    retrain_job_id = subprocess.getoutput(f\"tao-client {model_name} model-retrain --id {model_id} --job {prune_job_id}\")\n",
    "    print(retrain_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name != \"classification-pyt\":\n",
    "    # Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "    log_file = f\"{retrain_job_id}.txt\"\n",
    "    my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluate on retrained model <a class=\"anchor\" id=\"head-21-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name != \"classification-pyt\":\n",
    "    eval2_job_id = subprocess.getoutput(f\"tao-client {model_name} model-evaluate --id {model_id} --job {retrain_job_id}\")\n",
    "    print(eval2_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name != \"classification-pyt\":\n",
    "    log_file = f\"{eval2_job_id}.txt\"\n",
    "    my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide export specs <a class=\"anchor\" id=\"head-22\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default export model specs\n",
    "! tao-client {model_name} model-export-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/export.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize export model specs\n",
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'specs', 'export.json')\n",
    "\n",
    "with open(specs_path , \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "#Apply changes to the specs dictionary here if required\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run export <a class=\"anchor\" id=\"head-23\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "export_job_id = subprocess.getoutput(f\"tao-client {model_name} model-export --id {model_id} --job {train_job_id}\")\n",
    "print(export_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "log_file = f\"{export_job_id}.txt\"\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide trt engine generation specs <a class=\"anchor\" id=\"head-26\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default gen_trt_engine model specs\n",
    "! tao-client {model_name} model-gen-trt-engine-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/gen_trt_engine.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize gen_trt_engine model specs\n",
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'specs', 'gen_trt_engine.json')\n",
    "\n",
    "with open(specs_path , \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "#Apply changes to the specs dictionary here if required\n",
    "if model_name == \"classification-tf2\":\n",
    "    specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"fp16\"\n",
    "elif model_name == \"classification-pyt\":\n",
    "    specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"fp16\"\n",
    "else:\n",
    "    specs[\"data_type\"] = \"int8\"\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run TRT Engine generation using TAO-Deploy <a class=\"anchor\" id=\"head-27\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_trt_engine_job_id = subprocess.getoutput(f\"tao-client {model_name} model-gen-trt-engine --id {model_id} --job {export_job_id}\")\n",
    "print(gen_trt_engine_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "log_file = f\"{gen_trt_engine_job_id}.txt\"\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide TAO inference specs <a class=\"anchor\" id=\"head-28\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default inference model specs\n",
    "! tao-client {model_name} model-inference-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/inference.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize TAO inference specs\n",
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'specs', 'inference.json')\n",
    "\n",
    "with open(specs_path , \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "#Apply changes to the specs dictionary here if required\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run TAO inference <a class=\"anchor\" id=\"head-29\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tlt_inference_job_id = subprocess.getoutput(f\"tao-client {model_name} model-inference --id {model_id} --job {train_job_id}\")\n",
    "print(tlt_inference_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "log_file = f\"{tlt_inference_job_id}.txt\"\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_dir = f\"{home}/shared/users/{os.environ['USER']}/models/{model_id}/{tlt_inference_job_id}\"\n",
    "# You can find the predicted results here\n",
    "!ls {job_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide TRT inference specs <a class=\"anchor\" id=\"head-30\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default inference model specs\n",
    "! tao-client {model_name} model-inference-defaults --id {model_id} | tee ~/shared/users/{os.environ['USER']}/models/{model_id}/specs/inference.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize TAO inference specs\n",
    "specs_path = os.path.join(home, 'shared', 'users', os.environ['USER'], 'models', model_id, 'specs', 'inference.json')\n",
    "\n",
    "with open(specs_path , \"r\") as specs_file:\n",
    "    specs = json.load(specs_file)\n",
    "\n",
    "#Apply changes to the specs dictionary here if required\n",
    "\n",
    "with open(specs_path, \"w\") as specs_file:\n",
    "    json.dump(specs, specs_file, indent=2)\n",
    "\n",
    "print(json.dumps(specs, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run TRT inference <a class=\"anchor\" id=\"head-31\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trt_inference_job_id = subprocess.getoutput(f\"tao-client {model_name} model-inference --id {model_id} --job {gen_trt_engine_job_id}\")\n",
    "print(trt_inference_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "log_file = f\"{trt_inference_job_id}.txt\"\n",
    "my_tail(logs_dir, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_dir = f\"{home}/shared/users/{os.environ['USER']}/models/{model_id}/{tlt_inference_job_id}\"\n",
    "# You can find the predicted results here\n",
    "!ls {job_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Delete experiment <a class=\"anchor\" id=\"head-30\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! rm -rf ~/shared/users/{os.environ['USER']}/models/{model_id}\n",
    "! echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Delete datasets <a class=\"anchor\" id=\"head-31\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{train_dataset_id}\n",
    "! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{eval_dataset_id}\n",
    "! rm -rf ~/shared/users/{os.environ['USER']}/datasets/{infer_dataset_id}\n",
    "! echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unmount shared volume <a class=\"anchor\" id=\"head-32\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "command = \"umount ~/shared\"\n",
    "! echo {password} | sudo -S -k {command} && echo DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninstall TAO Remote Client <a class=\"anchor\" id=\"head-33\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip3 uninstall -y nvidia-tao-client"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
